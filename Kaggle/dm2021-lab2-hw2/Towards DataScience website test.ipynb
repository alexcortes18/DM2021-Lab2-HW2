{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "546b9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d15950a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.read_csv(\"preprocessed_data.csv\")\n",
    "twitter_test = pd.read_csv(\"twitter_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ab0b3ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>0x2e7caf</td>\n",
       "      <td>my  sunday lineup  girlstrip power  üí™üèæüòé</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>784</td>\n",
       "      <td>0x2eff99</td>\n",
       "      <td>therell never be a  time than now to  what you...</td>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358</td>\n",
       "      <td>0x3813a3</td>\n",
       "      <td>taluuluu riiiiiiiiiiiiiiiiight üôÑ</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x362eaa</td>\n",
       "      <td>never give up on your dream  me to make your ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367</td>\n",
       "      <td>0x286e23</td>\n",
       "      <td>pearlharper youre the most responsible adult i...</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317658</th>\n",
       "      <td>887</td>\n",
       "      <td>0x27028e</td>\n",
       "      <td>i better go eat something because i havent eat...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317659</th>\n",
       "      <td>574</td>\n",
       "      <td>0x30ffbb</td>\n",
       "      <td>russia had no bearing on electionpresident did...</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317660</th>\n",
       "      <td>91</td>\n",
       "      <td>0x29ccd4</td>\n",
       "      <td>artziiflower beingsalmankhan that meansnow u d...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317661</th>\n",
       "      <td>532</td>\n",
       "      <td>0x345ac6</td>\n",
       "      <td>talkmaster  now in greenville schigh of  enjoy...</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317662</th>\n",
       "      <td>33</td>\n",
       "      <td>0x3812f6</td>\n",
       "      <td>always going to walk in gods light watch me sh...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317663 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _score  tweet_id                                               text  \\\n",
       "0          299  0x2e7caf            my  sunday lineup  girlstrip power  üí™üèæüòé   \n",
       "1          784  0x2eff99  therell never be a  time than now to  what you...   \n",
       "2          358  0x3813a3                  taluuluu riiiiiiiiiiiiiiiiight üôÑ    \n",
       "3         1021  0x362eaa   never give up on your dream  me to make your ...   \n",
       "4          367  0x286e23  pearlharper youre the most responsible adult i...   \n",
       "...        ...       ...                                                ...   \n",
       "317658     887  0x27028e  i better go eat something because i havent eat...   \n",
       "317659     574  0x30ffbb  russia had no bearing on electionpresident did...   \n",
       "317660      91  0x29ccd4  artziiflower beingsalmankhan that meansnow u d...   \n",
       "317661     532  0x345ac6  talkmaster  now in greenville schigh of  enjoy...   \n",
       "317662      33  0x3812f6  always going to walk in gods light watch me sh...   \n",
       "\n",
       "       identification       emotion  Category  \n",
       "0               train          fear         1  \n",
       "1               train         trust         2  \n",
       "2               train         anger         3  \n",
       "3               train  anticipation         4  \n",
       "4               train      surprise         5  \n",
       "...               ...           ...       ...  \n",
       "317658          train  anticipation         4  \n",
       "317659          train         anger         3  \n",
       "317660          train       sadness         8  \n",
       "317661          train          fear         1  \n",
       "317662          train  anticipation         4  \n",
       "\n",
       "[317663 rows x 6 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aec8c86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>989</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310</td>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>602</td>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>598</td>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>827</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>368</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>498</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _score  tweet_id                                               text  \\\n",
       "0          232  0x28b412  Confident of your obedience, I write to you, k...   \n",
       "1          989  0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "2           66  0x218443  When do you have enough ? When are you satisfi...   \n",
       "3          104  0x2939d5  God woke you up, now chase the day #GodsPlan #...   \n",
       "4          310  0x26289a  In these tough times, who do YOU turn to as yo...   \n",
       "...        ...       ...                                                ...   \n",
       "411967     602  0x2913b4  \"For this is the message that ye heard from th...   \n",
       "411968     598  0x2a980e  \"There is a lad here, which hath five barley l...   \n",
       "411969     827  0x316b80  When you buy the last 2 tickets remaining for ...   \n",
       "411970     368  0x29d0cb  I swear all this hard work gone pay off one da...   \n",
       "411971     498  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...   \n",
       "\n",
       "       identification  \n",
       "0                test  \n",
       "1                test  \n",
       "2                test  \n",
       "3                test  \n",
       "4                test  \n",
       "...               ...  \n",
       "411967           test  \n",
       "411968           test  \n",
       "411969           test  \n",
       "411970           test  \n",
       "411971           test  \n",
       "\n",
       "[411972 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0ec14",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2acd9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the dataframe into a train and a test sections\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Choose either Category or emotion\n",
    "x_train,x_test,y_train,y_test = train_test_split(twitter,twitter.Category,\n",
    "                                                test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6139c402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((254130, 6), (63533, 6), (254130,), (63533,))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "993e8f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255439    5\n",
       "59813     8\n",
       "101110    6\n",
       "212739    2\n",
       "43393     1\n",
       "         ..\n",
       "119879    1\n",
       "259178    7\n",
       "131932    6\n",
       "146867    3\n",
       "121958    6\n",
       "Name: Category, Length: 254130, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d08732d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  [1 2 3 4 5 6 7 8]\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 255439    5\n",
      "59813     8\n",
      "101110    6\n",
      "212739    2\n",
      "Name: Category, dtype: int64\n",
      "\n",
      "y_train.shape:  (254130,)\n",
      "y_test.shape:  (63533,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (254130, 8)\n",
      "y_test.shape:  (63533, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    #return keras.utils.to_categorical(enc)\n",
    "    return keras.utils.np_utils.to_categorical(enc)   #Allison/Moo said so, because of version\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "905b4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokenizer for our data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(x_train[\"text\"])\n",
    "\n",
    "\n",
    "#convert text data to numerical indexes\n",
    "train_seqs=tokenizer.texts_to_sequences(x_train[\"text\"])\n",
    "test_seqs=tokenizer.texts_to_sequences(x_test[\"text\"])\n",
    "\n",
    "train_seqs=tf.keras.preprocessing.sequence.pad_sequences(train_seqs, maxlen=256, padding=\"post\")\n",
    "test_seqs=tf.keras.preprocessing.sequence.pad_sequences(test_seqs, maxlen=256, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8915d45",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b9662db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((254130, 256), (254130,))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seqs.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0734119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, None, 16)          160000    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,019\n",
      "Trainable params: 160,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "9149/9149 [==============================] - 18s 2ms/step - loss: -15.4347 - accuracy: 0.1228 - val_loss: -31.5659 - val_accuracy: 0.1227\n",
      "Epoch 2/20\n",
      "9149/9149 [==============================] - 18s 2ms/step - loss: -47.1874 - accuracy: 0.1254 - val_loss: -63.4748 - val_accuracy: 0.12277.0727 - accuracy: \n",
      "1986/1986 [==============================] - 2s 907us/step - loss: -63.1594 - accuracy: 0.1245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-63.159420013427734, 0.12450222671031952]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(10000, embedding_dim),\n",
    "  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max')\n",
    "callbacks = [es] #Early Stopping\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(train_seqs, y_train\n",
    "                    , batch_size = BATCH_SIZE\n",
    "                    , epochs = EPOCHS\n",
    "                    , validation_split = 0.1\n",
    "                    , callbacks = callbacks)\n",
    "\n",
    "model.evaluate(test_seqs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bf954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23391af2",
   "metadata": {},
   "source": [
    "## Continue from here:\n",
    "https://towardsdatascience.com/tensorflow-2-0-data-transformation-for-text-classification-b86ee2ad8877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b24216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2845d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
