{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4308fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012f51f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#twitter = pd.read_csv(\"preprocessed_data.csv\")    #normal one used before\n",
    "twitter = pd.read_csv(\"before_balancing_data.csv\") \n",
    "#twitter = pd.read_csv(\"sorted_preprocessed_data.csv\")  #with lowest emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07e22de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>people who post add me on snapchat must be deh...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>brianklaas as we see trump is dangerous to fre...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>now issa is stalking tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>riskshow thekevinallison thx for the best time...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>still waiting on those supplies liscus</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451432</th>\n",
       "      <td>94</td>\n",
       "      <td>0x321566</td>\n",
       "      <td>im so happy nowonder the name of this show hap...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451433</th>\n",
       "      <td>627</td>\n",
       "      <td>0x38959e</td>\n",
       "      <td>in every circumtance id like to be thankful to...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451434</th>\n",
       "      <td>274</td>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>theres currently two girls walking around the ...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451435</th>\n",
       "      <td>840</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>ah corporate life where you can date  using ju...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451436</th>\n",
       "      <td>360</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>blessed to be living sundayvibes</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451437 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _score  tweet_id                                               text  \\\n",
       "0           391  0x376b20  people who post add me on snapchat must be deh...   \n",
       "1           433  0x2d5350  brianklaas as we see trump is dangerous to fre...   \n",
       "2           376  0x1cd5b0                    now issa is stalking tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚    \n",
       "3           120  0x1d755c  riskshow thekevinallison thx for the best time...   \n",
       "4          1021  0x2c91a8            still waiting on those supplies liscus    \n",
       "...         ...       ...                                                ...   \n",
       "1451432      94  0x321566  im so happy nowonder the name of this show hap...   \n",
       "1451433     627  0x38959e  in every circumtance id like to be thankful to...   \n",
       "1451434     274  0x2cbca6  theres currently two girls walking around the ...   \n",
       "1451435     840  0x24faed  ah corporate life where you can date  using ju...   \n",
       "1451436     360  0x34be8c                  blessed to be living sundayvibes    \n",
       "\n",
       "        identification       emotion  \n",
       "0                train  anticipation  \n",
       "1                train       sadness  \n",
       "2                train          fear  \n",
       "3                train           joy  \n",
       "4                train  anticipation  \n",
       "...                ...           ...  \n",
       "1451432          train           joy  \n",
       "1451433          train           joy  \n",
       "1451434          train           joy  \n",
       "1451435          train           joy  \n",
       "1451436          train           joy  \n",
       "\n",
       "[1451437 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6befb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "#Here we get the TF_IDF for the first 100 features:\n",
    "number_features = 69000\n",
    "\n",
    "tkzr = TweetTokenizer(strip_handles = True)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "                            lowercase=True,\n",
    "                            max_features= number_features,\n",
    "                            #max_df=0.8,\n",
    "                            #min_df=2,\n",
    "                            #ngram_range = (1,3),\n",
    "                            #stop_words = \"english\",\n",
    "                            tokenizer = tkzr.tokenize\n",
    "                            )\n",
    "\n",
    "vectors = tfidf_vectorizer.fit_transform(twitter['text'])\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502c7bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 60 epochs took 83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.5491201840930386\n"
     ]
    }
   ],
   "source": [
    "# validate: split into train and test\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, twitter['emotion'], test_size=0.2, random_state=42)\n",
    "\n",
    "# model\n",
    "lr = LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, max_iter=1000,\n",
    "                   multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
    "                   random_state=None, solver='saga', tol=0.0001, verbose=2,\n",
    "                   warm_start=False)\n",
    "\n",
    "#the ones that first worked were -> solver: liblinear  ;  multi_class: auto\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371a46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_test_data = pd.read_csv(\"twitter_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1529bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_twitter = tfidf_vectorizer.transform(twitter_test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c202a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predict = lr.predict(x_test_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad07344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412         trust\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a         trust\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80       sadness\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df = pd.DataFrame(columns = [[\"id\",\"emotion\"]])\n",
    "upload_df[\"id\"] = twitter_test_data[\"tweet_id\"]\n",
    "upload_df[\"emotion\"] = new_predict\n",
    "upload_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217aa9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df.to_csv(\"./uploads/logistic_try_2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
