{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6eabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5674e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twitter = pd.read_csv(\"final_dataset.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf90ba9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>people who post add me on snapchat must be deh...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>peopl who post add me on snapchat must be dehy...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>brianklaas as we see trump is dangerous to fre...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>brianklaa as we see trump is danger to freepre...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalk tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>riskshow thekevinallison thx for the best time...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>riskshow thekevinallison thx for the best time...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>still waiting on those supplies liscus</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>still wait on those suppli liscu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451386</th>\n",
       "      <td>94</td>\n",
       "      <td>0x321566</td>\n",
       "      <td>im so happy nowonder the name of this show hap...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>im so happi nowond the name of thi show happi ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451387</th>\n",
       "      <td>627</td>\n",
       "      <td>0x38959e</td>\n",
       "      <td>in every circumtance id like to be thankful to...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>in everi circumt id like to be thank to the al...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451388</th>\n",
       "      <td>274</td>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>theres currently two girls walking around the ...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>there current two girl walk around the librari...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451389</th>\n",
       "      <td>840</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>ah corporate life where you can date  using ju...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah corpor life where you can date use just the...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451390</th>\n",
       "      <td>360</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>blessed to be living sundayvibes</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>bless to be live sundayvib</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451391 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _score  tweet_id                                               text  \\\n",
       "0           391  0x376b20  people who post add me on snapchat must be deh...   \n",
       "1           433  0x2d5350  brianklaas as we see trump is dangerous to fre...   \n",
       "2           376  0x1cd5b0                    now issa is stalking tasha 😂😂😂    \n",
       "3           120  0x1d755c  riskshow thekevinallison thx for the best time...   \n",
       "4          1021  0x2c91a8            still waiting on those supplies liscus    \n",
       "...         ...       ...                                                ...   \n",
       "1451386      94  0x321566  im so happy nowonder the name of this show hap...   \n",
       "1451387     627  0x38959e  in every circumtance id like to be thankful to...   \n",
       "1451388     274  0x2cbca6  theres currently two girls walking around the ...   \n",
       "1451389     840  0x24faed  ah corporate life where you can date  using ju...   \n",
       "1451390     360  0x34be8c                  blessed to be living sundayvibes    \n",
       "\n",
       "        identification       emotion  \\\n",
       "0                train  anticipation   \n",
       "1                train       sadness   \n",
       "2                train          fear   \n",
       "3                train           joy   \n",
       "4                train  anticipation   \n",
       "...                ...           ...   \n",
       "1451386          train           joy   \n",
       "1451387          train           joy   \n",
       "1451388          train           joy   \n",
       "1451389          train           joy   \n",
       "1451390          train           joy   \n",
       "\n",
       "                                              text_stemmed  Category  \n",
       "0        peopl who post add me on snapchat must be dehy...         4  \n",
       "1        brianklaa as we see trump is danger to freepre...         8  \n",
       "2                              now issa is stalk tasha 😂😂😂         1  \n",
       "3        riskshow thekevinallison thx for the best time...         7  \n",
       "4                         still wait on those suppli liscu         4  \n",
       "...                                                    ...       ...  \n",
       "1451386  im so happi nowond the name of thi show happi ...         7  \n",
       "1451387  in everi circumt id like to be thank to the al...         7  \n",
       "1451388  there current two girl walk around the librari...         7  \n",
       "1451389  ah corpor life where you can date use just the...         7  \n",
       "1451390                         bless to be live sundayvib         7  \n",
       "\n",
       "[1451391 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5181c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(twitter.text_stemmed,twitter.emotion,\n",
    "                                                test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4945a9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>people who post add me on snapchat must be deh...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>peopl who post add me on snapchat must be dehy...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>brianklaas as we see trump is dangerous to fre...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>brianklaa as we see trump is danger to freepre...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalk tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>riskshow thekevinallison thx for the best time...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>riskshow thekevinallison thx for the best time...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>still waiting on those supplies liscus</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>still wait on those suppli liscu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>481</td>\n",
       "      <td>0x368e95</td>\n",
       "      <td>love knows no gender 😢😭</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>love know no gender 😢😭</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>827</td>\n",
       "      <td>0x249c0c</td>\n",
       "      <td>dstvngcare dstvng more highlights are being sh...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>dstvngcare dstvng more highlight are be shown ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>631</td>\n",
       "      <td>0x359db9</td>\n",
       "      <td>the ssm debate  a manufactured fantasy used to...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>the ssm debat a manufactur fantasi use to dist...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>839</td>\n",
       "      <td>0x23b037</td>\n",
       "      <td>i love suffering 🙃🙃 i love when valium does no...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>i love suffer 🙃🙃 i love when valium doe noth t...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>560</td>\n",
       "      <td>0x1fde89</td>\n",
       "      <td>can someone tell my why my feeds scroll back t...</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>can someon tell my whi my feed scroll back to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score  tweet_id                                               text  \\\n",
       "0     391  0x376b20  people who post add me on snapchat must be deh...   \n",
       "1     433  0x2d5350  brianklaas as we see trump is dangerous to fre...   \n",
       "2     376  0x1cd5b0                    now issa is stalking tasha 😂😂😂    \n",
       "3     120  0x1d755c  riskshow thekevinallison thx for the best time...   \n",
       "4    1021  0x2c91a8            still waiting on those supplies liscus    \n",
       "5     481  0x368e95                           love knows no gender 😢😭    \n",
       "6     827  0x249c0c  dstvngcare dstvng more highlights are being sh...   \n",
       "7     631  0x359db9  the ssm debate  a manufactured fantasy used to...   \n",
       "8     839  0x23b037  i love suffering 🙃🙃 i love when valium does no...   \n",
       "9     560  0x1fde89  can someone tell my why my feeds scroll back t...   \n",
       "\n",
       "  identification       emotion  \\\n",
       "0          train  anticipation   \n",
       "1          train       sadness   \n",
       "2          train          fear   \n",
       "3          train           joy   \n",
       "4          train  anticipation   \n",
       "5          train           joy   \n",
       "6          train       sadness   \n",
       "7          train  anticipation   \n",
       "8          train           joy   \n",
       "9          train         anger   \n",
       "\n",
       "                                        text_stemmed  Category  \n",
       "0  peopl who post add me on snapchat must be dehy...         4  \n",
       "1  brianklaa as we see trump is danger to freepre...         8  \n",
       "2                        now issa is stalk tasha 😂😂😂         1  \n",
       "3  riskshow thekevinallison thx for the best time...         7  \n",
       "4                   still wait on those suppli liscu         4  \n",
       "5                             love know no gender 😢😭         7  \n",
       "6  dstvngcare dstvng more highlight are be shown ...         8  \n",
       "7  the ssm debat a manufactur fantasi use to dist...         4  \n",
       "8  i love suffer 🙃🙃 i love when valium doe noth t...         7  \n",
       "9  can someon tell my whi my feed scroll back to ...         3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207ebb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16717</th>\n",
       "      <td>thi</td>\n",
       "      <td>0.015838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>love</td>\n",
       "      <td>0.015443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9445</th>\n",
       "      <td>life</td>\n",
       "      <td>0.014071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16520</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.012985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>day</td>\n",
       "      <td>0.012614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19374</th>\n",
       "      <td>👋🏾•••</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>diltotgaya</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>🎲</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19182</th>\n",
       "      <td>⠀</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19093</th>\n",
       "      <td>♣</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             term    weight\n",
       "16717         thi  0.015838\n",
       "9751         love  0.015443\n",
       "9445         life  0.014071\n",
       "16520       thank  0.012985\n",
       "3938          day  0.012614\n",
       "...           ...       ...\n",
       "19374       👋🏾•••  0.000005\n",
       "4310   diltotgaya  0.000005\n",
       "19317           🎲  0.000004\n",
       "19182           ⠀  0.000004\n",
       "19093           ♣  0.000003\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "BOW = TfidfVectorizer(tokenizer=nltk.word_tokenize, \n",
    "                      stop_words='english', \n",
    "                      #min_df=2,\n",
    "                      max_df = 0.6, \n",
    "                      max_features = 20000)\n",
    "                      \n",
    "x_train = BOW.fit_transform(x_train)\n",
    "x_test = BOW.transform(x_test)\n",
    "\n",
    "term_weight = np.asarray(x_train.mean(axis=0)).ravel().tolist()\n",
    "term_array = pd.DataFrame({'term': BOW.get_feature_names(), 'weight': term_weight})\n",
    "term_array.sort_values(by='weight', ascending=False, inplace=True)\n",
    "term_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12835c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"😕\" in BOW.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553c90d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4601f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680793            trust\n",
       "815757          sadness\n",
       "1124461        surprise\n",
       "352702          sadness\n",
       "352523            trust\n",
       "               ...     \n",
       "259178              joy\n",
       "1414414             joy\n",
       "131932              joy\n",
       "671155     anticipation\n",
       "121958     anticipation\n",
       "Name: emotion, Length: 1161112, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5763872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 680793        trust\n",
      "815757      sadness\n",
      "1124461    surprise\n",
      "352702      sadness\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (1161112,)\n",
      "y_test.shape:  (290279,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (1161112, 8)\n",
      "y_test.shape:  (290279, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    #return keras.utils.to_categorical(enc)\n",
    "    return keras.utils.np_utils.to_categorical(enc)   #Allison/Moo said so, because of version\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b50f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  20000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = x_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2e8e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1280064   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,284,744\n",
      "Trainable params: 1,284,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 10000\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64,32\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64,32\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "876398c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.sort_indices()\n",
    "x_test.sort_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393064a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18143/18143 [==============================] - 203s 11ms/step - loss: 1.3200 - accuracy: 0.5214 - val_loss: 1.2773 - val_accuracy: 0.5374\n",
      "Epoch 2/5\n",
      "18143/18143 [==============================] - 200s 11ms/step - loss: 1.2245 - accuracy: 0.5548 - val_loss: 1.2720 - val_accuracy: 0.5409\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "\n",
    "#csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 5 #25\n",
    "batch_size = 64 #32, 100\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max')\n",
    "callbacks = [es] #Early Stopping\n",
    "\n",
    "# training!\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = (x_test, y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "861e4590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14836648, 0.04212337, 0.15480943, 0.03308226, 0.21177396,\n",
       "        0.26413223, 0.05552765, 0.09018464],\n",
       "       [0.01731134, 0.30944312, 0.0403496 , 0.03917805, 0.27731386,\n",
       "        0.12049851, 0.03004997, 0.16585556],\n",
       "       [0.03144   , 0.03075863, 0.20133059, 0.01250601, 0.27844   ,\n",
       "        0.34669498, 0.0561654 , 0.04266438],\n",
       "       [0.04125348, 0.19344606, 0.16691317, 0.01574966, 0.43413737,\n",
       "        0.08184849, 0.04147959, 0.02517226],\n",
       "       [0.01214604, 0.05816235, 0.04672039, 0.02222294, 0.25231025,\n",
       "        0.44147667, 0.07884371, 0.08811763]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = model.predict(x_test, batch_size=128) #128\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6512d2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'anticipation', 'sadness', 'joy', 'sadness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51ca6374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91eea053",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_test_data = pd.read_csv(\"twitter_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d303b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape:  (411972, 20000)\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test_twitter = BOW.transform(twitter_test_data['text'])\n",
    "x_test_twitter.sort_indices()\n",
    "\n",
    "pred_result_test_data = model.predict(x_test_twitter, batch_size=128)\n",
    "\n",
    "print('x_test.shape: ', x_test_twitter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cdffe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'anticipation', 'joy', 'anticipation', 'trust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_test_data = label_decode(label_encoder, pred_result_test_data)\n",
    "pred_result_test_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ba77c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412           joy\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5  anticipation\n",
       "4       0x26289a         trust\n",
       "...          ...           ...\n",
       "411967  0x2913b4           joy\n",
       "411968  0x2a980e           joy\n",
       "411969  0x316b80       sadness\n",
       "411970  0x29d0cb         anger\n",
       "411971  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df = pd.DataFrame()\n",
    "upload_df[\"id\"] = twitter_test_data[\"tweet_id\"]\n",
    "upload_df[\"emotion\"] = pred_result_test_data\n",
    "upload_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c357dfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_df.emotion.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3767e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df.to_csv(\"./uploads/TF-IDF_20k.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907ea36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
